{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gpxL3Y54-mv",
        "outputId": "199498ce-efad-4c45-b570-0f382a48be0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Dataset generated and saved as iot_sensor_dataset_with_low_med_high_regions.csv\n",
            "OutbreakRisk\n",
            "Medium    1001\n",
            "High       500\n",
            "Low        499\n",
            "Name: count, dtype: int64\n",
            "   SampleID      State      Village  Water_pH  Turbidity_NTU  Chlorine_mg_L  \\\n",
            "0      1861  Meghalaya        Jowai      5.61           8.50           0.07   \n",
            "1       354    Manipur    Bishnupur      8.02           0.05           0.74   \n",
            "2      1334      Assam       Tezpur      5.62           1.91           0.25   \n",
            "3       906    Tripura  Kailashahar      5.97           4.13           0.26   \n",
            "4      1290   Nagaland     Touphema      5.78           4.01           0.27   \n",
            "5      1274    Mizoram     Thenzawl      8.94           4.87           0.27   \n",
            "6       939      Assam    Sualkuchi      6.32           2.01           0.27   \n",
            "7      1732  Meghalaya     Baghmara      5.89           5.92           0.14   \n",
            "8        66  Meghalaya        Dawki      7.16           0.47           0.34   \n",
            "9      1324  Meghalaya   Mawlynnong      6.09           3.56           0.26   \n",
            "\n",
            "  BacterialPresence  EColi_MPN  Rainfall_mm  AvgTemperature_C OutbreakRisk  \n",
            "0               Yes     141.58       118.64             26.53         High  \n",
            "1                No       0.83         0.81             29.29          Low  \n",
            "2                No      13.01        56.19             34.90       Medium  \n",
            "3                No      38.44        57.52             30.79       Medium  \n",
            "4                No      16.21        42.76             27.87       Medium  \n",
            "5                No      31.18        74.55             27.09       Medium  \n",
            "6                No       4.43        23.45             30.19       Medium  \n",
            "7               Yes     159.57       142.62             32.34         High  \n",
            "8                No       0.82        19.47             27.70          Low  \n",
            "9                No      17.92        32.45             34.85       Medium  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# State â†’ Village mapping\n",
        "STATE_VILLAGE_MAP = {\n",
        "    'Arunachal Pradesh': ['Ziro', 'Bomdila', 'Mechuka', 'Anini', 'Daporijo', 'Pasighat', 'Tuting'],\n",
        "    'Assam': ['Majuli', 'Sualkuchi', 'Hajo', 'Sivasagar', 'Barpeta', 'Tezpur', 'Goalpara', 'Digboi'],\n",
        "    'Manipur': ['Moirang', 'Andro', 'Noney', 'Ukhrul', 'Kakching', 'Bishnupur', 'Moreh'],\n",
        "    'Meghalaya': ['Mawlynnong', 'Cherrapunji', 'Nongriat', 'Dawki', 'Jowai', 'Baghmara', 'Tura'],\n",
        "    'Mizoram': ['Champhai', 'Hmuifang', 'Reiek', 'Falkawn', 'Thenzawl', 'Kolasib', 'Serchhip'],\n",
        "    'Nagaland': ['Khonoma', 'Touphema', 'Longwa', 'Mokokchung', 'Wokha', 'Mon', 'Phek'],\n",
        "    'Tripura': ['Udaipur', 'Ambassa', 'Kailashahar', 'Dharmanagar', 'Amarpur', 'Belonia', 'Sabroom']\n",
        "}\n",
        "\n",
        "# Risk logic function\n",
        "def assign_risk(row):\n",
        "    # High risk conditions\n",
        "    if row['EColi_MPN'] > 50 or row['BacterialPresence'] == \"Yes\" or (row['Turbidity_NTU'] > 5 and row['Chlorine_mg_L'] < 0.2):\n",
        "        return \"High\"\n",
        "    # Medium risk conditions\n",
        "    elif (row['Water_pH'] < 6.5 or row['Water_pH'] > 8.5) or (0.2 <= row['Chlorine_mg_L'] <= 0.3) or (1 <= row['EColi_MPN'] <= 50) or (row['Turbidity_NTU'] > 1):\n",
        "        return \"Medium\"\n",
        "    # Low risk conditions\n",
        "    elif (6.5 <= row['Water_pH'] <= 8.5) and (0.3 < row['Chlorine_mg_L'] <= 1.0) and (row['EColi_MPN'] < 1) and (row['BacterialPresence'] == \"No\") and (row['Turbidity_NTU'] <= 1):\n",
        "        return \"Low\"\n",
        "    # Fallback\n",
        "    else:\n",
        "        return \"Medium\"\n",
        "\n",
        "# Dataset generation\n",
        "def generate_iot_dataset(n_low=500, n_medium=1000, n_high=500, random_state=42):\n",
        "    np.random.seed(random_state)\n",
        "    random.seed(random_state)\n",
        "    rows = []\n",
        "    states = list(STATE_VILLAGE_MAP.keys())\n",
        "\n",
        "    # Low Risk\n",
        "    for i in range(n_low):\n",
        "        state = random.choice(states)\n",
        "        village = random.choice(STATE_VILLAGE_MAP[state])\n",
        "        row = {\n",
        "            \"SampleID\": i + 1,\n",
        "            \"State\": state,\n",
        "            \"Village\": village,\n",
        "            \"Water_pH\": round(random.uniform(6.5, 8.5), 2),\n",
        "            \"Turbidity_NTU\": round(random.uniform(0.0, 1.0), 2),\n",
        "            \"Chlorine_mg_L\": round(random.uniform(0.3, 1.0), 2),\n",
        "            \"BacterialPresence\": \"No\",\n",
        "            \"EColi_MPN\": round(random.uniform(0.0, 0.99), 2),\n",
        "            \"Rainfall_mm\": round(random.uniform(0, 50), 2),\n",
        "            \"AvgTemperature_C\": round(random.uniform(20, 30), 2),\n",
        "        }\n",
        "        row[\"OutbreakRisk\"] = assign_risk(row)\n",
        "        rows.append(row)\n",
        "\n",
        "    # Medium Risk\n",
        "    for i in range(n_medium):\n",
        "        state = random.choice(states)\n",
        "        village = random.choice(STATE_VILLAGE_MAP[state])\n",
        "        row = {\n",
        "            \"SampleID\": n_low + i + 1,\n",
        "            \"State\": state,\n",
        "            \"Village\": village,\n",
        "            \"Water_pH\": round(random.choice([random.uniform(5.5, 6.4), random.uniform(8.6, 9.5)]), 2),\n",
        "            \"Turbidity_NTU\": round(random.uniform(1.1, 5.0), 2),\n",
        "            \"Chlorine_mg_L\": round(random.uniform(0.2, 0.3), 2),\n",
        "            \"BacterialPresence\": \"No\",\n",
        "            \"EColi_MPN\": round(random.uniform(1, 50), 2),\n",
        "            \"Rainfall_mm\": round(random.uniform(20, 80), 2),\n",
        "            \"AvgTemperature_C\": round(random.uniform(25, 35), 2),\n",
        "        }\n",
        "        row[\"OutbreakRisk\"] = assign_risk(row)\n",
        "        rows.append(row)\n",
        "\n",
        "    # High Risk\n",
        "    for i in range(n_high):\n",
        "        state = random.choice(states)\n",
        "        village = random.choice(STATE_VILLAGE_MAP[state])\n",
        "        row = {\n",
        "            \"SampleID\": n_low + n_medium + i + 1,\n",
        "            \"State\": state,\n",
        "            \"Village\": village,\n",
        "            \"Water_pH\": round(random.uniform(4.5, 9.5), 2),\n",
        "            \"Turbidity_NTU\": round(random.uniform(5.1, 10.0), 2),\n",
        "            \"Chlorine_mg_L\": round(random.uniform(0.0, 0.19), 2),\n",
        "            \"BacterialPresence\": \"Yes\",\n",
        "            \"EColi_MPN\": round(random.uniform(51, 200), 2),\n",
        "            \"Rainfall_mm\": round(random.uniform(50, 150), 2),\n",
        "            \"AvgTemperature_C\": round(random.uniform(25, 40), 2),\n",
        "        }\n",
        "        row[\"OutbreakRisk\"] = assign_risk(row)\n",
        "        rows.append(row)\n",
        "\n",
        "    # Create DataFrame & shuffle\n",
        "    df = pd.DataFrame(rows)\n",
        "    df = df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "# Generate & Save Dataset\n",
        "df = generate_iot_dataset()\n",
        "df.to_csv(\"iot_sensor_dataset_regions.csv\", index=False)\n",
        "print(\" Dataset generated and saved as iot_sensor_dataset_with_low_med_high_regions.csv\")\n",
        "print(df['OutbreakRisk'].value_counts())\n",
        "print(df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"iot_sensor_dataset_regions.csv\")\n",
        "print(df[\"OutbreakRisk\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZofMJ0SLImHu",
        "outputId": "65f323dd-0c38-4a81-93ce-a7cb77503f93"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OutbreakRisk\n",
            "Medium    1001\n",
            "High       500\n",
            "Low        499\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from collections import Counter\n",
        "import joblib\n",
        "\n",
        "# Load dataset (with State + Village present)\n",
        "data = pd.read_csv(\"iot_sensor_dataset_regions.csv\")\n",
        "\n",
        "# Features and target\n",
        "X = data.drop(columns=[\"OutbreakRisk\", \"State\", \"Village\"])  # âŒ exclude regions from training\n",
        "y = data[\"OutbreakRisk\"]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Define IoT features\n",
        "numeric_features = [\n",
        "    \"Water_pH\",\n",
        "    \"Turbidity_NTU\",\n",
        "    \"Chlorine_mg_L\",\n",
        "    \"EColi_MPN\",\n",
        "    \"Rainfall_mm\",\n",
        "    \"AvgTemperature_C\"\n",
        "]\n",
        "\n",
        "categorical_features = [\"BacterialPresence\"]\n",
        "\n",
        "# Transformers\n",
        "numeric_transformer = StandardScaler()\n",
        "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        (\"cat\", categorical_transformer, categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Handle class imbalance with SMOTE\n",
        "max_count = max(Counter(y_train).values())\n",
        "smote_strategy = {cls: max_count for cls in Counter(y_train).keys()}\n",
        "smote = SMOTE(sampling_strategy=smote_strategy, random_state=42)\n",
        "\n",
        "# Classifier\n",
        "classifier = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Full pipeline\n",
        "pipeline = ImbPipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"smote\", smote),\n",
        "    (\"classifier\", classifier)\n",
        "])\n",
        "\n",
        "# Train pipeline\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Save pipeline\n",
        "joblib.dump(pipeline, \"final_pipeline_balanced.joblib\")  # âœ… same name you use in prediction\n",
        "print(\"âœ… Pipeline saved as 'final_pipeline_balanced.joblib'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mShpZrEK5RdX",
        "outputId": "a25e5cd2-0446-4356-e1f4-d584524fc2c9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        High       1.00      1.00      1.00       100\n",
            "         Low       1.00      1.00      1.00       100\n",
            "      Medium       1.00      1.00      1.00       200\n",
            "\n",
            "    accuracy                           1.00       400\n",
            "   macro avg       1.00      1.00      1.00       400\n",
            "weighted avg       1.00      1.00      1.00       400\n",
            "\n",
            "Confusion Matrix:\n",
            " [[100   0   0]\n",
            " [  0 100   0]\n",
            " [  0   0 200]]\n",
            "âœ… Pipeline saved as 'final_pipeline_balanced.joblib'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# Load trained pipeline\n",
        "pipeline = joblib.load(\"final_pipeline_balanced.joblib\")\n",
        "\n",
        "def predict_with_region(sample_data: dict, state: str, village: str):\n",
        "    # Only IoT features go into the model\n",
        "    iot_features = {k: sample_data[k] for k in [\n",
        "        \"Water_pH\", \"Turbidity_NTU\", \"Chlorine_mg_L\",\n",
        "        \"EColi_MPN\", \"Rainfall_mm\", \"AvgTemperature_C\", \"BacterialPresence\"\n",
        "    ]}\n",
        "\n",
        "    df = pd.DataFrame([iot_features])\n",
        "\n",
        "    # Predict\n",
        "    pred_class = pipeline.predict(df)[0]\n",
        "    pred_proba = pipeline.predict_proba(df)[0]\n",
        "\n",
        "    # Confidence\n",
        "    class_labels = pipeline.classes_\n",
        "    pred_idx = list(class_labels).index(pred_class)\n",
        "    pred_confidence = pred_proba[pred_idx] * 100\n",
        "\n",
        "    # Final output (with region just for display)\n",
        "    return f\"Predicted Risk: {pred_class} ({pred_confidence:.2f}%) in {village}, {state}\"\n",
        "\n",
        "\n",
        "# âœ… Example usage\n",
        "sample = {\n",
        "    \"Water_pH\": 7.0,\n",
        "    \"Turbidity_NTU\": 0.4,\n",
        "    \"Chlorine_mg_L\": 0.35,\n",
        "    \"EColi_MPN\": 0,\n",
        "    \"Rainfall_mm\": 20,\n",
        "    \"AvgTemperature_C\": 28,\n",
        "    \"BacterialPresence\": \"No\"\n",
        "}\n",
        "\n",
        "print(predict_with_region(sample, state=\"Assam\", village=\"Majuli\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqk2Ygz3ByFi",
        "outputId": "e49d7443-5080-4178-dec5-b1397fd750ca"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Risk: Low (100.00%) in Majuli, Assam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "# Load trained pipeline\n",
        "pipeline = joblib.load(\"final_pipeline_balanced_with_regions.joblib\")\n",
        "\n",
        "# ðŸ”´ High Risk Sample\n",
        "sample_high = {\n",
        "    \"State\": \"Assam\",\n",
        "    \"Village\": \"Majuli\",\n",
        "    \"Water_pH\": 6.0,\n",
        "    \"Turbidity_NTU\": 4.5,\n",
        "    \"Chlorine_mg_L\": 0.05,\n",
        "    \"BacterialPresence\": \"Yes\",\n",
        "    \"EColi_MPN\": 150,\n",
        "    \"Rainfall_mm\": 40,\n",
        "    \"AvgTemperature_C\": 30\n",
        "}\n",
        "\n",
        "# ðŸŸ¡ Medium Risk Sample\n",
        "sample_medium = {\n",
        "    \"State\": \"Meghalaya\",\n",
        "    \"Village\": \"Cherrapunji\",\n",
        "    \"Water_pH\": 6.2,\n",
        "    \"Turbidity_NTU\": 3.5,\n",
        "    \"Chlorine_mg_L\": 0.25,\n",
        "    \"BacterialPresence\": \"No\",\n",
        "    \"EColi_MPN\": 20,\n",
        "    \"Rainfall_mm\": 60,\n",
        "    \"AvgTemperature_C\": 29\n",
        "}\n",
        "\n",
        "# ðŸŸ¢ Low Risk Sample\n",
        "sample_low = {\n",
        "    \"State\": \"Assam\",\n",
        "    \"Village\": \"Sivasagar\",\n",
        "    \"Water_pH\": 7.0,\n",
        "    \"Turbidity_NTU\": 0.4,\n",
        "    \"Chlorine_mg_L\": 0.35,\n",
        "    \"EColi_MPN\": 0.35,\n",
        "    \"Rainfall_mm\": 20,\n",
        "    \"AvgTemperature_C\": 28,\n",
        "    \"BacterialPresence\": \"No\"\n",
        "}\n",
        "\n",
        "# Function to predict and print nicely\n",
        "def predict_outbreak(sample):\n",
        "    df = pd.DataFrame([sample])\n",
        "    pred_class = pipeline.predict(df)[0]\n",
        "    pred_proba = pipeline.predict_proba(df)[0]\n",
        "\n",
        "    class_labels = pipeline.classes_\n",
        "    pred_idx = list(class_labels).index(pred_class)\n",
        "    pred_confidence = pred_proba[pred_idx] * 100\n",
        "\n",
        "    print(\n",
        "        f\"Predicted Risk: {pred_class} ({pred_confidence:.2f}%) \"\n",
        "        f\"in {sample['Village']}, {sample['State']}\"\n",
        "    )\n",
        "\n",
        "# Run predictions\n",
        "print(\"\\nðŸ”´ High Risk Sample:\")\n",
        "predict_outbreak(sample_high)\n",
        "\n",
        "print(\"\\nðŸŸ¡ Medium Risk Sample:\")\n",
        "predict_outbreak(sample_medium)\n",
        "\n",
        "print(\"\\nðŸŸ¢ Low Risk Sample:\")\n",
        "predict_outbreak(sample_low)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfPYuZAWCqDd",
        "outputId": "69322271-13a7-49fe-890e-bfc1704e7bdf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”´ High Risk Sample:\n",
            "Predicted Risk: High (73.48%) in Majuli, Assam\n",
            "\n",
            "ðŸŸ¡ Medium Risk Sample:\n",
            "Predicted Risk: Medium (95.88%) in Cherrapunji, Meghalaya\n",
            "\n",
            "ðŸŸ¢ Low Risk Sample:\n",
            "Predicted Risk: Low (94.96%) in Sivasagar, Assam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cbvWPiGkDk1S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}