{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "032bb2e8",
   "metadata": {},
   "source": [
    "# ML Model for Predicting Disease Outbreak Risk (Multiple Classifiers)\n",
    "\n",
    "This notebook builds and compares several machine learning models using the refined ASHA worker dataset. The goal is to identify the best-performing classifier for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfc21600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05dc2a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the new realistic dataset with CommunityNotes.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset created by the updated data_synthesizer.py\n",
    "df = pd.read_csv('truly_realistic_dataset.csv')\n",
    "\n",
    "# Drop location identifiers as they are not predictive features for a general model\n",
    "df = df.drop(columns=['State', 'District'])\n",
    "\n",
    "print(\"Successfully loaded the new realistic dataset with CommunityNotes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891e9fca",
   "metadata": {},
   "source": [
    "### 3. Preprocess Data (Structured + NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "144e8b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing with NLP complete.\n",
      "Final training data shape: (4000, 59)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('OutbreakStatus', axis=1)\n",
    "y = df['OutbreakStatus']\n",
    "\n",
    "# Identify column types\n",
    "categorical_features = X.select_dtypes(include=['object']).drop(columns=['CommunityNotes']).columns.tolist()\n",
    "boolean_features = X.select_dtypes(include=['bool']).columns.tolist()\n",
    "text_feature = 'CommunityNotes'\n",
    "\n",
    "# Create the preprocessor for structured data (categorical & boolean)\n",
    "structured_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', drop='first'), categorical_features),\n",
    "        ('bool', 'passthrough', boolean_features)\n",
    "    ], \n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Create the preprocessor for the text data\n",
    "text_preprocessor = TfidfVectorizer(stop_words='english', max_features=50, ngram_range=(1,2))\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Split data before processing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Apply preprocessing to each part and combine\n",
    "X_train_structured = structured_preprocessor.fit_transform(X_train)\n",
    "X_test_structured = structured_preprocessor.transform(X_test)\n",
    "\n",
    "X_train_text = text_preprocessor.fit_transform(X_train[text_feature])\n",
    "X_test_text = text_preprocessor.transform(X_test[text_feature])\n",
    "\n",
    "X_train_final = hstack([X_train_structured, X_train_text]).tocsr()\n",
    "X_test_final = hstack([X_test_structured, X_test_text]).tocsr()\n",
    "\n",
    "print(\"Preprocessing with NLP complete.\")\n",
    "print(\"Final training data shape:\", X_train_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3907619c",
   "metadata": {},
   "source": [
    "### 4. Hyperparameter Tuning with GridSearchCV\n",
    "\n",
    "We will tune the two most promising models: RandomForest and LightGBM. GridSearchCV will exhaustively test combinations of parameters to find the best set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d742f378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tuning RandomForestClassifier ---\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      "Best RandomForest Parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best RandomForest CV Score: 0.79325\n",
      "\n",
      "--- Tuning LGBMClassifier ---\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      "Best LightGBM Parameters: {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 100, 'num_leaves': 20}\n",
      "Best LightGBM CV Score: 0.7987500000000001\n"
     ]
    }
   ],
   "source": [
    "# --- RandomForest Tuning ---\n",
    "print(\"--- Tuning RandomForestClassifier ---\")\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42, n_jobs=-1), param_grid_rf, cv=5, scoring='accuracy', verbose=1)\n",
    "grid_rf.fit(X_train_final, y_train)\n",
    "\n",
    "print(\"\\nBest RandomForest Parameters:\", grid_rf.best_params_)\n",
    "print(\"Best RandomForest CV Score:\", grid_rf.best_score_)\n",
    "\n",
    "# --- LightGBM Tuning ---\n",
    "print(\"\\n--- Tuning LGBMClassifier ---\")\n",
    "param_grid_lgbm = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'num_leaves': [20, 31, 40],\n",
    "    'learning_rate': [0.1, 0.05],\n",
    "    'max_depth': [-1, 10]\n",
    "}\n",
    "grid_lgbm = GridSearchCV(LGBMClassifier(random_state=42, verbosity=-1), param_grid_lgbm, cv=5, scoring='accuracy', verbose=1)\n",
    "grid_lgbm.fit(X_train_final, y_train)\n",
    "\n",
    "print(\"\\nBest LightGBM Parameters:\", grid_lgbm.best_params_)\n",
    "print(\"Best LightGBM CV Score:\", grid_lgbm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03a0887d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- The best overall model is: Tuned LightGBM ---\n",
      "\n",
      "Final Test Set Accuracy: 0.8310\n",
      "\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   High_Risk       0.80      0.80      0.80       428\n",
      "    Low_Risk       0.85      0.85      0.85       572\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.83      0.83      0.83      1000\n",
      "weighted avg       0.83      0.83      0.83      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare the best scores from the tuned models\n",
    "if grid_rf.best_score_ > grid_lgbm.best_score_:\n",
    "    best_model = grid_rf.best_estimator_\n",
    "    best_model_name = 'Tuned RandomForest'\n",
    "else:\n",
    "    best_model = grid_lgbm.best_estimator_\n",
    "    best_model_name = 'Tuned LightGBM'\n",
    "\n",
    "print(f\"--- The best overall model is: {best_model_name} ---\")\n",
    "\n",
    "# Evaluate the final model on the unseen test data\n",
    "y_pred = best_model.predict(X_test_final)\n",
    "final_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nFinal Test Set Accuracy: {final_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00971151",
   "metadata": {},
   "source": [
    "### 6. Save the Complete Tuned Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8a7304a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the best model 'Tuned LightGBM' and all pipeline components.\n",
      "\n",
      "All pipeline components have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Saving the best model '{best_model_name}' and all pipeline components.\")\n",
    "\n",
    "# Save all components\n",
    "with open('best_model.pkl', 'wb') as f: pickle.dump(best_model, f)\n",
    "with open('structured_preprocessor.pkl', 'wb') as f: pickle.dump(structured_preprocessor, f)\n",
    "with open('text_preprocessor.pkl', 'wb') as f: pickle.dump(text_preprocessor, f)\n",
    "with open('label_encoder.pkl', 'wb') as f: pickle.dump(le, f)\n",
    "    \n",
    "print(\"\\nAll pipeline components have been saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d221fb",
   "metadata": {},
   "source": [
    "### 7. Example: Loading and Using the Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5d60910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pipeline components loaded successfully.\n",
      "\n",
      "New sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WaterSourceType</th>\n",
       "      <th>SanitationLevels</th>\n",
       "      <th>Fever</th>\n",
       "      <th>Vomiting</th>\n",
       "      <th>AbdominalPain</th>\n",
       "      <th>RecentTravelHistory</th>\n",
       "      <th>CommunityNotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HandPump</td>\n",
       "      <td>Poor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>High Fever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  WaterSourceType SanitationLevels  Fever  Vomiting  AbdominalPain  \\\n",
       "0        HandPump             Poor   True     False           True   \n",
       "\n",
       "   RecentTravelHistory CommunityNotes  \n",
       "0                False     High Fever  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Prediction: High_Risk (Encoded: 0)\n"
     ]
    }
   ],
   "source": [
    "# Load all saved objects\n",
    "loaded_model = pickle.load(open('best_model.pkl', 'rb'))\n",
    "loaded_structured_preprocessor = pickle.load(open('structured_preprocessor.pkl', 'rb'))\n",
    "loaded_text_preprocessor = pickle.load(open('text_preprocessor.pkl', 'rb'))\n",
    "loaded_label_encoder = pickle.load(open('label_encoder.pkl', 'rb'))\n",
    "print(\"All pipeline components loaded successfully.\")\n",
    "\n",
    "# Create a sample of new data -- YOU CAN PLAY WITH THESE FIELDS\n",
    "sample_data = pd.DataFrame({\n",
    "    'WaterSourceType': ['HandPump'],\n",
    "    'SanitationLevels': ['Poor'],\n",
    "    'Fever': [True],\n",
    "    'Vomiting': [False],\n",
    "    'AbdominalPain': [True],\n",
    "    'RecentTravelHistory': [False],\n",
    "    'CommunityNotes': [\"High Fever\"]\n",
    "})\n",
    "\n",
    "print(\"\\nNew sample data:\")\n",
    "display(sample_data)\n",
    "\n",
    "# Transform the new data using the correct preprocessors\n",
    "transformed_structured = loaded_structured_preprocessor.transform(sample_data)\n",
    "transformed_text = loaded_text_preprocessor.transform(sample_data['CommunityNotes'])\n",
    "\n",
    "# Combine the transformed parts\n",
    "transformed_sample = hstack([transformed_structured, transformed_text]).tocsr()\n",
    "\n",
    "# Make a prediction\n",
    "prediction_encoded = loaded_model.predict(transformed_sample)\n",
    "prediction = loaded_label_encoder.inverse_transform(prediction_encoded)\n",
    "\n",
    "print(f\"\\nModel Prediction: {prediction[0]} (Encoded: {prediction_encoded[0]})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
